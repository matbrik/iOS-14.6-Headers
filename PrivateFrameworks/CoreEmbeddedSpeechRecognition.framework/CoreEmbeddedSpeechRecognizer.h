/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/CoreEmbeddedSpeechRecognition.framework/CoreEmbeddedSpeechRecognition
 */

@interface CoreEmbeddedSpeechRecognizer : NSObject <AFSpeechServiceDelegate, CoreEmbeddedSpeechRecognizerProvider> {
    NSString * _currentLanguage;
    <CoreEmbeddedSpeechRecognizerDelegate> * _delegate;
    NSXPCConnection * _esConnection;
    bool  _hasRecognizedAnything;
    unsigned char  _instanceUUID;
    NSData * _preheatedProfile;
    NSString * _preheatedProfileAssetPath;
    NSObject<OS_dispatch_queue> * _queue;
    bool  _recognitionActive;
    NSError * _recognitionError;
}

@property (readonly, copy) NSString *debugDescription;
@property (nonatomic, readonly) <CoreEmbeddedSpeechRecognizerDelegate> *delegate;
@property (readonly, copy) NSString *description;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;

+ (id)dictionaryWithContentsProfilePathForLanguage:(id)arg1 errorOut:(id*)arg2;
+ (id)installedAssetSizeWithError:(id*)arg1;
+ (id)offlineDictationStatusIgnoringCache:(bool)arg1 error:(id*)arg2;
+ (id)profilePathForLanguage:(id)arg1 errorOut:(id*)arg2;
+ (id)purgeInstalledAssetsExceptLanguages:(id)arg1 error:(id*)arg2;
+ (void)resetCacheAndCompileAllAssets;
+ (id)speechProfileDataLastModifiedDataForLanguage:(id)arg1;

- (void).cxx_destruct;
- (id)_connection;
- (id)_newConnection;
- (id)_service;
- (id)_serviceWithFunctionName:(id)arg1 errorHandler:(id /* block */)arg2;
- (id)_synchronousServiceWithErrorHandler:(id /* block */)arg1;
- (void)addAudioPacket:(id)arg1;
- (void)createSpeechProfileWithLanguage:(id)arg1 modelOverridePath:(id)arg2 JSONData:(id)arg3 completion:(id /* block */)arg4;
- (id)delegate;
- (void)deleteAllDESRecordsForDictationPersonalization;
- (void)fetchAssetsForLanguage:(id)arg1 completion:(id /* block */)arg2;
- (void)fetchUserDataForLanguage:(id)arg1 completion:(id /* block */)arg2;
- (void)finishAudio;
- (void)getOfflineDictationStatusIgnoringCache:(bool)arg1 withCompletion:(id /* block */)arg2;
- (void)getOfflineDictationStatusWithCompletion:(id /* block */)arg1;
- (id)init;
- (id)initWithDelegate:(id)arg1 instanceUUID:(unsigned char)arg2;
- (unsigned char*)instanceUUID;
- (void)invalidate;
- (void)invalidatePersonalizedLM;
- (void)preheatSpeechRecognitionWithLanguage:(id)arg1 modelOverrideURL:(id)arg2;
- (void)readProfileAndUserDataWithLanguage:(id)arg1 allowOverride:(bool)arg2 completion:(id /* block */)arg3;
- (void)removePersonalizedLMForFidesOnly:(bool)arg1;
- (void)resetDESWithCompletion:(id /* block */)arg1;
- (void)runAdaptationRecipeEvaluation:(id)arg1 recordData:(id)arg2 attachments:(id)arg3 completion:(id /* block */)arg4;
- (void)runEvaluationWithDESRecordDatas:(id)arg1 language:(id)arg2 recipe:(id)arg3 fidesPersonalizedLMPath:(id)arg4 fidesPersonalizedLMTrainingAsset:(id)arg5 scrubResult:(bool)arg6 completion:(id /* block */)arg7;
- (void)sendSpeechCorrectionInfo:(id)arg1 interactionIdentifier:(id)arg2;
- (oneway void)speechServiceDidFinishRecognitionWithStatistics:(id)arg1 error:(id)arg2;
- (oneway void)speechServiceDidProcessAudioDuration:(double)arg1;
- (oneway void)speechServiceDidRecognizePackage:(id)arg1;
- (oneway void)speechServiceDidRecognizeRawEagerRecognitionCandidate:(id)arg1;
- (oneway void)speechServiceDidRecognizeTokens:(id)arg1;
- (void)startSpeechRecognitionWithLanguage:(id)arg1 interactionIdentifier:(id)arg2 task:(id)arg3 context:(id)arg4 narrowband:(bool)arg5 detectUtterances:(bool)arg6 maximumRecognitionDuration:(double)arg7 farField:(bool)arg8 secureOfflineOnly:(bool)arg9 censorSpeech:(bool)arg10 originalAudioFileURL:(id)arg11 overrides:(id)arg12 modelOverrideURL:(id)arg13 applicationName:(id)arg14 shouldStoreAudioOnDevice:(bool)arg15 didStartHandler:(id /* block */)arg16;
- (void)updateSpeechProfileWithLanguage:(id)arg1 modelOverridePath:(id)arg2 completion:(id /* block */)arg3;
- (void)writeDESRecord;

@end
