/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/AVConference.framework/AVConference
 */

@interface VCAVFoundationCapture : VCVideoCapture <AVCaptureDataOutputSynchronizerDelegate, AVCaptureMetadataOutputObjectsDelegate, AVCaptureVideoDataOutputSampleBufferDelegate, VCEffectsManagerDelegate, VCVideoSource> {
    int  _activeFrameRate;
    int  _activeHeight;
    int  _activeWidth;
    NSMutableArray * _cachedDataArray;
    AVCaptureDevice * _captureDevice;
    AVCaptureSession * _captureSession;
    NSObject<OS_dispatch_queue> * _captureSessionQueue;
    struct CGSize { 
        double width; 
        double height; 
    }  _captureSize;
    AVCaptureDepthDataOutput * _depthDataOutput;
    float  _depthFrameRateMultplier;
    bool  _deviceSupportCFraming;
    bool  _effectsApplied;
    bool  _faceMeshTrackingEnabled;
    bool  _forceDynamicEffectsFramerate;
    bool  _forceMirrorCapture;
    bool  _forcePearlCamera;
    int  _frameCount;
    VCImageResizingConverter * _imageCopyingConverter;
    VCImageMirroringConverter * _imageMirroringConverter;
    VCImageResizingConverter * _imageResizingConverter;
    VCImageRotationConverter * _imageRotationConverter;
    bool  _isCapturing;
    bool  _isPreviewing;
    bool  _isProcessMediaserverd;
    int  _lastClientRequestedFrameRate;
    struct { 
        long long value; 
        int timescale; 
        unsigned int flags; 
        long long epoch; 
    }  _lastPrintTimestamp;
    struct { 
        long long value; 
        int timescale; 
        unsigned int flags; 
        long long epoch; 
    }  _lastReceivedTimestamp;
    struct { 
        long long value; 
        int timescale; 
        unsigned int flags; 
        long long epoch; 
    }  _lastSentTimestamp;
    AVCaptureMetadataOutput * _metadataOutput;
    AVCaptureDataOutputSynchronizer * _outputSynchronizer;
    NSMutableArray * _outputSynchronizerOutputs;
    float  _processTimeSum;
    int  _receivedFrameCount;
    NSMutableArray * _renderFrameTimes;
    struct CGSize { 
        double width; 
        double height; 
    }  _requestSize;
    bool  _resize;
    int  _sentFrameCount;
    AVCaptureVideoDataOutput * _videoCaptureOutput;
    AVCaptureDeviceInput * _videoDeviceInput;
    NSObject<OS_dispatch_queue> * _viewPointCorrectionQueue;
    bool  _viewPointCorrectionThermalEnabled;
    VCViewpointCorrection * _viewpointCorrection;
    float  _viewpointProcessTime;
}

@property (readonly, copy) NSString *debugDescription;
@property (nonatomic, readonly) AVCaptureDepthDataOutput *depthDataOutput;
@property (readonly, copy) NSString *description;
@property bool effectsApplied;
@property bool faceMeshTrackingEnabled;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;

- (void)attachMetadata:(id)arg1 toCVPixelBuffer:(struct __CVBuffer { }*)arg2;
- (id)cameraFormatForWidth:(int)arg1 height:(int)arg2;
- (id)cameraFormatForWidth:(int)arg1 height:(int)arg2 frameRate:(int)arg3;
- (bool)cameraSupportsFormatWidth:(int)arg1 height:(int)arg2;
- (bool)cameraSupportsNoQueueFormatWidth:(int)arg1 height:(int)arg2;
- (void)captureOutput:(id)arg1 didOutputMetadataObjects:(id)arg2 fromConnection:(id)arg3;
- (void)captureOutput:(id)arg1 didOutputSampleBuffer:(struct opaqueCMSampleBuffer { }*)arg2 fromConnection:(id)arg3;
- (void)captureSessionNotification:(id)arg1;
- (long long)captureTierForEncodingSize:(struct CGSize { double x1; double x2; })arg1;
- (void)checkCameraZoomCapability;
- (void)configureCaptureDeviceDepthFormat;
- (int)configureCaptureWithToken:(struct _VCVideoSourceToken { union { struct { unsigned int x_1_2_1 : 24; unsigned int x_1_2_2 : 8; } x_1_1_1; unsigned int x_1_1_2; } x1; })arg1;
- (void)configureMetadataTypesForOutput:(id)arg1;
- (int)copyColorInfo:(const struct __CFDictionary {}**)arg1;
- (void)dataOutputSynchronizer:(id)arg1 didOutputSynchronizedDataCollection:(id)arg2;
- (void)dealloc;
- (id)depthDataOutput;
- (bool)effectsApplied;
- (void)encodeProcessedPixelBuffer:(struct __CVBuffer { }*)arg1 time:(struct { long long x1; int x2; unsigned int x3; long long x4; })arg2 imageData:(id)arg3 processTime:(id)arg4;
- (bool)faceMeshTrackingEnabled;
- (int)frameBecameAvailableCount:(int*)arg1 figBufferQueueEmptyCount:(int*)arg2 figBufferQueueErrorCount:(int*)arg3;
- (int)frameCount:(bool)arg1;
- (void)frameCount:(int*)arg1 averageProcessTime:(float*)arg2;
- (struct { long long x1; int x2; unsigned int x3; long long x4; })frameDurationForVideoDeviceFormat:(id)arg1 frameRate:(int)arg2;
- (struct CGSize { double x1; double x2; })getBestCaptureSizeForEncodingSize:(struct CGSize { double x1; double x2; })arg1;
- (int)getMaxAllowedFrameRate:(int)arg1;
- (id)initWithCaptureServer:(id)arg1 width:(int)arg2 height:(int)arg3 frameRate:(int)arg4 videoSourceToken:(struct _VCVideoSourceToken { union { struct { unsigned int x_1_2_1 : 24; unsigned int x_1_2_2 : 8; } x_1_1_1; unsigned int x_1_1_2; } x1; })arg5;
- (void)initializeDepthDataOutput;
- (void)initializeMetadataOutput;
- (void)initializeOutputs;
- (void)initializeSynchronizedOutputs;
- (void)initializeVideoCaptureOutput;
- (bool)isBackCamera;
- (bool)isFormatMaxFrameRateSupported:(id)arg1 frameRate:(int)arg2;
- (bool)isFrontCamera;
- (bool)isPreviewRunning;
- (bool)isVideoDeviceInputSupportCFraming:(id)arg1;
- (struct opaqueCMSampleBuffer { }*)newResizedFrame:(struct opaqueCMSampleBuffer { }*)arg1 time:(struct { long long x1; int x2; unsigned int x3; long long x4; })arg2;
- (void)prepareSynchronizedOutputs:(id)arg1;
- (void)processSampleBuffer:(struct opaqueCMSampleBuffer { }*)arg1 depthData:(id)arg2 faceData:(id)arg3 captureDevice:(id)arg4;
- (void)processViewPointCorrection:(struct opaqueCMSampleBuffer { }*)arg1 metaData:(id)arg2 shouldProcess:(bool)arg3;
- (void)resetViewPointLogging;
- (void)sendImageDataForSampleBuffer:(struct opaqueCMSampleBuffer { }*)arg1 depthData:(id)arg2 faceData:(id)arg3 captureDevice:(id)arg4 originalSize:(struct CGSize { double x1; double x2; })arg5;
- (void)setCFramingEnabled:(bool)arg1;
- (int)setCamera:(struct _VCVideoSourceToken { union { struct { unsigned int x_1_2_1 : 24; unsigned int x_1_2_2 : 8; } x_1_1_1; unsigned int x_1_1_2; } x1; })arg1 width:(int)arg2 height:(int)arg3 frameRate:(int)arg4;
- (void)setCameraZoomFactor:(double)arg1;
- (void)setCameraZoomFactor:(double)arg1 withRate:(double)arg2;
- (void)setEffectsApplied:(bool)arg1;
- (void)setFaceMeshTrackingEnabled:(bool)arg1;
- (int)setFrameRate:(int)arg1;
- (int)setFrameRateInternal:(int)arg1;
- (int)setVideoDeviceToSelectedDevice:(id)arg1;
- (int)setVideoDeviceToWidth:(int)arg1 height:(int)arg2 frameRate:(int)arg3;
- (void)setVideoOrientationAndMirroredForDevice:(id)arg1;
- (void)setVideoStabilizationTo:(bool)arg1;
- (void)setViewPointCorrectionEnabaled:(bool)arg1;
- (int)setWidth:(int)arg1 height:(int)arg2 frameRate:(int)arg3;
- (bool)shouldAddDepthData;
- (bool)shouldAddTrackedFacesData;
- (bool)shouldResizeWithCaptureSize:(struct CGSize { double x1; double x2; })arg1 requestSize:(struct CGSize { double x1; double x2; })arg2;
- (bool)shouldUseCameraVideoStabilization;
- (bool)shouldUseViewpointCorrection;
- (int)startCaptureWithWidth:(int)arg1 height:(int)arg2 frameRate:(int)arg3;
- (int)startPreview;
- (int)stop:(bool)arg1;
- (bool)supportsViewpointCorrection;
- (void)tearDownSynchronizer;
- (void)updateDepthFrameRate;
- (void)updateRenderProcessFrameRate:(id)arg1;
- (void)updateVideoCaptureServerWithSampleBuffer:(struct opaqueCMSampleBuffer { }*)arg1 time:(struct { long long x1; int x2; unsigned int x3; long long x4; })arg2 frontCamera:(bool)arg3 shouldMirrorFrontPreview:(bool)arg4 isFromEffects:(bool)arg5;

@end
